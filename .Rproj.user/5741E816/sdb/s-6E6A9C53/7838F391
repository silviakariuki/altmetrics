{
    "contents" : "---\ntitle: \"On the origin of citations\"\nauthor: \"Silvia Kariuki\"\ndate: \"September 15, 2015\"\noutput:\n  word_document: default\n  html_document:\n    fig_caption: yes\n    fig_height: 8\n    fig_width: 8\n    highlight: espresso\n    number_sections: yes\n    self_contained: no\n    theme: cerulean\n    toc: yes\n---\n\n# Load the data\n\n## using read.delim\n\n```{r load_data}\ncounts_raw <- read.delim(\"data/counts-raw.txt.gz\")\ncounts_norm <- read.delim(\"data/counts-norm.txt.gz\")\n```\n\n\n# Data exploration\n\nWhat's the distribution of authors in all articles of our data set?\n\n```{r author_histogram, echo = FALSE, fig.cap=\"Figure 1: Number of Authors per Article\"}\nhist(counts_raw$authorsCount, main=\"Authors per paper\", xlab=\"# authors\")\n```\n\n```{r facebook_shares, echo = FALSE, fig.cap=\"Figure 2: Number of Facebook Shares per Article\"}\nhist(counts_raw$facebookShareCount, main=\"Facebook shares per article\", xlab=\"# Facebook shares\")\n```\n\nThe average number of Facebook shares per paper in the data set is `r mean(counts_raw$facebookShareCount)`\n\n## dplyr\n\n```{r}\nlibrary(\"dplyr\")\n```\n\n\n```{r}\nresearch <- filter(counts_raw, articleType == \"Research Article\")\n```\n\n\n```{r}\nresearch_2006 <- filter(research, year == 2006)\nnrow(research_2006)\n```\n\n```{r}\nresearch_2006_fb <- filter(research, year == 2006,\n                           facebookCommentCount > 0)\nnrow(research_2006_fb)\n```\n\n```{r}\nresearch_2006_fb_tweet_disease <- filter(research, year == 2006,\n                           facebookCommentCount > 0 | backtweetsCount > 0,\n                           grepl(\"Infectious Diseases\", plosSubjectTags))\n\nnrow(research_2006_fb_tweet_disease)\n\n```\n\n```{r}\ncolnames(research)\n```\n\n```{r}\narticle_info <- select(research, doi, pubDate, journal, title, articleType, authorsCount)\ncolnames(article_info)\n```\n\n```{r}\narticle_info <- select(research, doi:authorsCount)\ncolnames(article_info)\n```\n\n```{r}\nmetrics <- select(research, contains(\"Count\"), -authorsCount, f1000Factor, wikipediaCites)\ncolnames(metrics)\n```\n\n```{r}\nhead(select(research, journal))\nhead(select(research, 3))\n```\n\n```{r}\nslice(article_info, 1:3)\n```\n\n```{r}\nlow_cite <- filter(research, year <= 2008, \n                   pdfDownloadsCount > 1000,\n                   mendeleyReadersCount > 15, \n                   wosCountThru2011 < 10)\n\nnrow(low_cite)\nselect(low_cite,title)\n```\n\n\n### Chaining commands with dplyr\n\n\npipe character %>%\n\n```{r}\nfacebook_2006 <- research %>% filter(year == 2006) %>% select(contains(\"facebook\"))\nhead(facebook_2006)\n```\n\n\n```{r}\nresearch %>% filter(year == 2006) %>% select(contains(\"facebook\")) %>% \n  nrow\n```\n\n\narrange, works similar to function order\n\n```{r}\nresearch %>% arrange(desc(authorsCount), desc(wosCountThru2011)) %>% \n  select(authorsCount, wosCountThru2011) %>% \n  slice(1:10)\n```\n\n\n```{r}\nresearch %>% arrange(desc(wosCountThru2011)) %>% slice(1:3) %>% select(title) %>% head(3)\n```\n\n```{r}\nresearch %>% arrange(desc(authorsCount)) %>% \n  select(authorsCount, title, journal, plosSubjectTags) %>% \n  slice(1:3)\n```\n\n\n### summarizing with dplyr\n\n```{r}\nresearch <- research %>% mutate(weeksSincePublished = daysSincePublished / 7, \n                                yearsSincePublished = weeksSincePublished / 52)\nresearch %>% select(contains(\"Since\")) %>% slice(1:10)\n```\n\n\nusing summarize\n\n```{r}\nresearch %>% summarize(plos_mean = mean(plosCommentCount),\n                       plos_sd = sd(plosCommentCount),\n                       num = n())\n```\n\n\n## Using group_by\n\n```{r}\nresearch %>% group_by(journal, year) %>%\n  summarize(tweets_mean = mean(backtweetsCount))\n```\n\n\n```{r}\ntweets_per_journal <- research %>% group_by(journal) %>%\n  summarize(num = n(),\n            tweets_mean = mean(backtweetsCount),\n            tweets_SEM = sd(backtweetsCount) / sqrt(num))\n```\n\n\n## ggplot2\n\n\n```{r}\nlibrary(\"ggplot2\")\n```\n\n\n\n```{r}\np <- ggplot(research, aes(x = pdfDownloadsCount, \n                          y = wosCountThru2011, \n                          color = journal)) + \n  geom_point() + \n  geom_smooth()\np\n\n```\n\nCreate a scatter plot with daysSincePublished mapped to the x-axis and wosCountThru2011 mapped to the y-axis. Include a loess fit of the data. Set the transparency level (alpha) of the points to 0.5 and color the points according to the journal where the article was published. Make the loess curve red.\n\n\n```{r}\np <- ggplot(research, aes(x = daysSincePublished, \n                          y = wosCountThru2011, \n                          color = journal)) + \n  geom_point(aes(color = journal), alpha = 0.5) + \n  geom_smooth(color = \"red\")\np\n```\n\n\n### Using scales\n\n```{r}\np <- ggplot(research, aes(x = log10(pdfDownloadsCount + 1),\n                          y = log10(wosCountThru2011 + 1))) +\n  geom_point(aes(color = journal)) +\n  geom_smooth() + \n  scale_x_continuous(breaks = c(1,3), labels = c(10, 1000)) + \n  scale_y_continuous(breaks = c(1,3), labels = c(10, 1000),\n                     limits = c(1,3))\np\n\n```\n\n\ndifferent color options\n\n```{r}\np + scale_color_grey()\np + scale_color_manual(values = c(\"red\", \"green\", \"blue\", \"orange\", \"pink\", \"yellow\", \"purple\"))\n```\n\n\n```{r}\nlibrary(\"RColorBrewer\")\ndisplay.brewer.all(type = \"qual\")\n```\n\n\n```{r}\np + scale_color_brewer(palette = \"Dark2\",\n                       labels = 1:7, name = \"PLOS\")\n```\n\n\nUpdate the plot to use a square root transformation instead of log10. Also color the points using the ColorBrewer palette “Accent”.\n\n```{r}\np <- ggplot(research, aes(x = sqrt(pdfDownloadsCount),\n                          y = sqrt(wosCountThru2011))) +\n  geom_point(aes(color = journal)) +\n  geom_smooth() + \n  scale_color_brewer(palette = \"Accent\")\np\n```\n\n\nUsing facets to make subplots\n\n\n```{r}\np <- ggplot(research, aes(x = sqrt(pdfDownloadsCount),\n                          y = sqrt(wosCountThru2011))) +\n  geom_point(aes(color = journal)) +\n  geom_smooth() + \n  scale_color_brewer(palette = \"Accent\")\np + facet_wrap(~journal, ncol = 2)\n```\n\n\nUsing facet_grid\n\n```{r}\nresearch <- mutate(research, immuno = grepl(\"Immunology\", plosSubjectTags))\np + facet_grid(journal~immuno)\n```\n\n```{r}\np <- ggplot(research, aes(x = sqrt(pdfDownloadsCount),\n                          y = sqrt(wosCountThru2011))) +\n  geom_point(aes(color = journal)) +\n  geom_smooth() + \n  scale_color_brewer(palette = \"Accent\")\np + facet_grid(journal~immuno)\n```\n\n\nUsing different geoms\n\n```{r}\np <- ggplot(research, aes(x = journal,\n                          y = sqrt(wosCountThru2011))) +\n  geom_boxplot()\np\n```\n\n\nmaking a barplot\n\n```{r}\ntweets_per_journal <- research %>% group_by(journal) %>%\n  summarize(num = n(),\n            mean = mean(backtweetsCount),\n            sem = sd(backtweetsCount) / sqrt(num))\ntweets_per_journal\n```\n\n\n```{r}\ntweets_bar <- ggplot(tweets_per_journal, aes(x = journal, y = mean)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = 0.1) + \n  geom_text(aes(label = num), hjust = 0, vjust = 0)\ntweets_bar\n```\n\n\nModify the dplyr code above to calculate the mean, SEM, and sample size of the number of article tweets per journal and per year. Use facet_wrap to make a separate subplot per year.\n\n```{r}\ntweets_per_journal <- research %>% group_by(journal, year) %>%\n  summarize(num = n(),\n            mean = mean(backtweetsCount),\n            sem = sd(backtweetsCount) / sqrt(num))\ntweets_per_journal\n```\n\n\n```{r}\ntweets_bar <- ggplot(tweets_per_journal, aes(x = journal, y = mean)) +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = 0.1) + \n  geom_text(aes(label = num), hjust = 0, vjust = 0)\ntweets_bar + facet_wrap(~year)\n```\n\n\nThe geoms geom_histogram and geom_density can be used to create histograms and density plots, respectively. Using these geoms, visualize the distribution of 2011 citations (wosCountThru2011). Compare the raw distribution to log10 and square root transformations.\n\n```{r}\np <- ggplot(research, aes(x = journal, \n                          y = sqrt(wosCountThru2011))) +\n  geom_histogram(stat = \"identity\")\np\n```\n\n\n```{r}\np <- ggplot(research, aes(x = journal, \n                          y = sqrt(wosCountThru2011))) +\n  geom_density(stat = \"identity\")\np\n```\n\n",
    "created" : 1442332840139.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2682528331",
    "id" : "7838F391",
    "lastKnownWriteTime" : 1442353044,
    "path" : "~/altmetrics/altmetrics_analyses.Rmd",
    "project_path" : "altmetrics_analyses.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}